{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from agent import *\n",
    "from selection import *\n",
    "from utils import *\n",
    "from env import Environment\n",
    "from simulation import constructAgent, twoSimulate\n",
    "from main import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN vs TfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_convergence(agent:object, threshold:int, k:int=100):\n",
    "    if agent.play_times < 2*k:\n",
    "        return False\n",
    "    history_1 = agent.own_memory[agent.play_times-k:agent.play_times]\n",
    "    history_2 = agent.own_memory[agent.play_times-2*k:agent.play_times-k]\n",
    "    difference = torch.sum(torch.abs(history_1 - history_2))\n",
    "    if difference > threshold:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 9.324725299452743, average of loss (interval is 20): 9.414865579550641, average of loss (interval is 100): 9.450661483407021\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.902885661084409, average of loss (interval is 20): 7.005591902314831, average of loss (interval is 100): 7.062497464815776\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 5.653982754085405, average of loss (interval is 20): 5.321225471591869, average of loss (interval is 100): 6.503893848260244\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 6.82774464047675, average of loss (interval is 20): 6.74333912113433, average of loss (interval is 100): 6.725889675617218\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.574592383217992, average of loss (interval is 20): 6.054236715003772, average of loss (interval is 100): 4.858311032829806\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.089824750491644, average of loss (interval is 20): 6.134413682279133, average of loss (interval is 100): 6.742297476530075\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 5.197439733702116, average of loss (interval is 20): 5.459676912092433, average of loss (interval is 100): 4.316258647463595\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 6.911621563430138, average of loss (interval is 20): 6.8262815355914555, average of loss (interval is 100): 7.022427393170074\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 5.5623245531882155, average of loss (interval is 20): 5.647553008835332, average of loss (interval is 100): 5.758048395315806\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.803550884665602, average of loss (interval is 20): 6.789858971728759, average of loss (interval is 100): 8.201774982611338\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.3009175160666295, average of loss (interval is 20): 6.484965439480381, average of loss (interval is 100): 7.211732057730357\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 7.028620657392959, average of loss (interval is 20): 7.015586238911183, average of loss (interval is 100): 7.103290288001299\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 6.537210634067925, average of loss (interval is 20): 6.897947821870144, average of loss (interval is 100): 7.27646872852929\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 6.607432438664605, average of loss (interval is 20): 7.081418718610491, average of loss (interval is 100): 6.105883546670278\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 7.200568665540513, average of loss (interval is 20): 6.820559029275106, average of loss (interval is 100): 5.668600932359696\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 7.2752669695132255, average of loss (interval is 20): 7.250444826493442, average of loss (interval is 100): 6.776682499051094\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# choices = {'0-alwaysCooperate','1-alwaysDefect','2-titForTat','3-reverseTitForTat','4-random','5-grudger','6-pavlov','7-qLearning','8-lstm-TFT','9-dqn','10-lstmqn','11-a2c','12-a2c-lstm'}\n",
    "# rl_choices = {'7-qLearning','8-lstm-pavlov','9-dqn','10-lstmqn','11-a2c','12-a2c-lstm'}\n",
    "strategies = {0:'ALLC',1:'ALLD',2:'TitForTat',3:'revTitForTat',4:'Random',5:'Grudger',6:'Pavlov',7:'QLearning',8:'LSTM',9:'DQN',10:'LSTMQN',11:'A2C',12:'A2CLSTM'}\n",
    "\n",
    "h = [1,2,5,10]\n",
    "epsilon_decay = [0.95, 0.99, 0.995, 0.999]\n",
    "\n",
    "config = {\n",
    "    'reward': 3, \n",
    "    'sucker': 0, \n",
    "    'temptation': 5, \n",
    "    'punishment': 1, \n",
    "    'n_episodes': 10000, \n",
    "    'discount': 0.99,\n",
    "    'play_epsilon': 1,\n",
    "    'select_epsilon': 1,\n",
    "    'epsilon_decay': 0.999,\n",
    "    'min_epsilon': 0.01,\n",
    "    'alpha': 0.1,\n",
    "    'n_actions': 2,\n",
    "    'h': 10,\n",
    "    'state_repr': 'bi',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "}\n",
    "\n",
    "epsilon_dict = {'epsilon_decay=0.95':[],'epsilon_decay=0.99':[],'epsilon_decay=0.995':[],'epsilon_decay=0.999':[]}\n",
    "result_dict={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "                \n",
    "for key in result_dict:\n",
    "    result_dict[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        num = 2\n",
    "        rl_num = 9\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            # twoSimulate(dict({num: strategies[num],rl_num: strategies[rl_num]}), rl_num, config)\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict[f'h={i}'][f'epsilon_decay={j}'].append(np.mean(agent2.loss))\n",
    "                strategy_dict[f'h={i}'][f'epsilon_decay={j}'].append(list(agent2.own_memory[agent2.play_times-10:agent2.play_times]))\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "    # plt.plot(agent2.loss[::20])\n",
    "    # plt.title(f'agent:{agent2.name}')\n",
    "    # plt.show()\n",
    "# agent1.show()\n",
    "# agent2.show()\n",
    "# print(\"==================================================\")\n",
    "# print(f'{agent1.name} score: {agent1.running_score}\\n{agent2.name} score: {agent2.running_score}')\n",
    "# print(\"------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "# print()\n",
    "\n",
    "# x = [i for i in range(0, agent1.play_times)]\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.plot(x, agent1.own_memory[0:agent1.play_times], label=agent1.name, alpha=0.5)\n",
    "# plt.plot(x, agent2.own_memory[0:agent2.play_times], label=agent2.name, alpha=0.5)\n",
    "# plt.legend()\n",
    "# plt.ylim(-0.5, 2)\n",
    "# plt.xlim(0, agent1.play_times)\n",
    "# plt.title(f'agent:{agent1.name} vs agent:{agent2.name}')\n",
    "# plt.savefig(f'images/{agent1.name}vs{agent2.name}_result_h={config.h}.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h=1': {'epsilon_decay=0.95': [3000, 3000, 3000, 3000, 4000], 'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000], 'epsilon_decay=0.995': [4000, 3000, 20000, 3000, 3000], 'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]}, 'h=2': {'epsilon_decay=0.95': [3000, 20000, 3000, 2000, 3000], 'epsilon_decay=0.99': [3000, 4000, 3000, 3000, 3000], 'epsilon_decay=0.995': [3000, 7000, 3000, 3000, 3000], 'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]}, 'h=5': {'epsilon_decay=0.95': [5000, 3000, 3000, 3000, 3000], 'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000], 'epsilon_decay=0.995': [3000, 3000, 3000, 4000, 3000], 'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]}, 'h=10': {'epsilon_decay=0.95': [3000, 5000, 3000, 3000, 4000], 'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000], 'epsilon_decay=0.995': [3000, 6000, 20000, 7000, 5000], 'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]}}\n",
      "\n",
      "{'h=1': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, 'h=2': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, 'h=5': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]]}, 'h=10': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]}}\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        strategy_dict[f'h={i}'][f'epsilon_decay={j}'] = torch.Tensor(strategy_dict[f'h={i}'][f'epsilon_decay={j}']).numpy().astype(int).tolist()\n",
    "print(result_dict)\n",
    "print()\n",
    "print(strategy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.84565812599636\n",
      "6.681979909030754\n",
      "6.685040653032973\n",
      "6.696518058278707\n",
      "5.219096498522428\n",
      "6.6952139011328855\n",
      "6.726328886213844\n",
      "6.935448207144164\n",
      "6.702649024437409\n",
      "6.949632831592234\n",
      "6.9972721526957375\n",
      "7.1748613247461845\n",
      "7.147196131551553\n",
      "6.770848050045555\n",
      "8.551492503719853\n",
      "6.891393396063504\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(loss_dict[f'h={i}'][f'epsilon_decay={j}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN vs DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 9.74302608461709, average of loss (interval is 20): 10.596129937853835, average of loss (interval is 100): 9.4769208105281\n",
      "length of loss: 3936, average of loss (interval is 2): 10.071894292226553, average of loss (interval is 20): 10.309910644696751, average of loss (interval is 100): 9.359448426775634\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 9.600981240357628, average of loss (interval is 20): 9.171886406271591, average of loss (interval is 100): 9.538195848464966\n",
      "length of loss: 3936, average of loss (interval is 2): 9.990633483828477, average of loss (interval is 20): 9.74006481582138, average of loss (interval is 100): 8.828737169504166\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 7.433507197191206, average of loss (interval is 20): 7.315761974725944, average of loss (interval is 100): 7.219819411933422\n",
      "length of loss: 19936, average of loss (interval is 2): 8.011420079626292, average of loss (interval is 20): 8.194621022664096, average of loss (interval is 100): 8.051793173551559\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 4.989018139575657, average of loss (interval is 20): 4.825642231788763, average of loss (interval is 100): 4.68976128295064\n",
      "length of loss: 19936, average of loss (interval is 2): 4.944216366506421, average of loss (interval is 20): 4.894359733373648, average of loss (interval is 100): 5.099941685555969\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 5.737584503568514, average of loss (interval is 20): 5.735994415594977, average of loss (interval is 100): 5.604390819370747\n",
      "length of loss: 19936, average of loss (interval is 2): 7.818089832200102, average of loss (interval is 20): 7.876479961770169, average of loss (interval is 100): 7.847074970602989\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 6.018086762277015, average of loss (interval is 20): 5.971550513413868, average of loss (interval is 100): 5.90263383179903\n",
      "length of loss: 19936, average of loss (interval is 2): 6.761478335436106, average of loss (interval is 20): 6.602632756517787, average of loss (interval is 100): 6.4658804918825625\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 18000\n",
      "length of loss: 17936, average of loss (interval is 2): 4.638915348538724, average of loss (interval is 20): 4.506984884041874, average of loss (interval is 100): 4.738085516624981\n",
      "length of loss: 17936, average of loss (interval is 2): 5.1471531365291625, average of loss (interval is 20): 5.172713773288227, average of loss (interval is 100): 5.686806823747854\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 6.52319530593037, average of loss (interval is 20): 6.557398638281684, average of loss (interval is 100): 6.701802389472723\n",
      "length of loss: 19936, average of loss (interval is 2): 5.248350487586487, average of loss (interval is 20): 5.379713990894653, average of loss (interval is 100): 5.292443474978208\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 18000\n",
      "length of loss: 17936, average of loss (interval is 2): 5.836067956506942, average of loss (interval is 20): 5.678077070381484, average of loss (interval is 100): 5.497612179256976\n",
      "length of loss: 17936, average of loss (interval is 2): 6.964631073925616, average of loss (interval is 20): 7.123391723648594, average of loss (interval is 100): 7.106798424488968\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 8.495803955698678, average of loss (interval is 20): 8.886770137675523, average of loss (interval is 100): 8.96929079592228\n",
      "length of loss: 3936, average of loss (interval is 2): 8.891394637457882, average of loss (interval is 20): 8.548432196154812, average of loss (interval is 100): 9.10576032847166\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 3.9588613113371416, average of loss (interval is 20): 3.9671407282770934, average of loss (interval is 100): 4.140764471739531\n",
      "length of loss: 19936, average of loss (interval is 2): 5.539355762942225, average of loss (interval is 20): 5.50355157079857, average of loss (interval is 100): 5.750341550037265\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1.])\n",
      "Oppo action: tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 5.088191294386373, average of loss (interval is 20): 5.0399483912806575, average of loss (interval is 100): 5.004467831254005\n",
      "length of loss: 19936, average of loss (interval is 2): 5.2053362093118425, average of loss (interval is 20): 5.146758954108897, average of loss (interval is 100): 4.866015731692314\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing times: 11000\n",
      "length of loss: 10936, average of loss (interval is 2): 11.49228885657806, average of loss (interval is 20): 11.618063856631354, average of loss (interval is 100): 11.271099874648181\n",
      "length of loss: 10936, average of loss (interval is 2): 13.133397008050178, average of loss (interval is 20): 12.947969336260172, average of loss (interval is 100): 12.110137082907286\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 6.12775451077845, average of loss (interval is 20): 6.061126431601576, average of loss (interval is 100): 5.861278599724174\n",
      "length of loss: 19936, average of loss (interval is 2): 5.032747965510763, average of loss (interval is 20): 5.155075607367361, average of loss (interval is 100): 5.426575713604689\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 4.15116969142893, average of loss (interval is 20): 4.122732728495522, average of loss (interval is 100): 4.020071800500155\n",
      "length of loss: 19936, average of loss (interval is 2): 5.4441349816423195, average of loss (interval is 20): 5.4656852186697655, average of loss (interval is 100): 5.688972697556019\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 5.648900173320458, average of loss (interval is 20): 5.701638000719287, average of loss (interval is 100): 5.663389894366264\n",
      "length of loss: 19936, average of loss (interval is 2): 5.765501407529698, average of loss (interval is 20): 5.580466899165179, average of loss (interval is 100): 5.345797252058983\n",
      "==================================================\n",
      "Your action: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_dqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict_dqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_dqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "\n",
    "for key in result_dict_dqn:\n",
    "    result_dict_dqn[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict_dqn[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_dqn[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        rl_num = 9\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[rl_num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_dqn[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict_dqn[f'h={i}'][f'epsilon_decay={j}'].append([np.mean(agent1.loss),np.mean(agent2.loss)])\n",
    "                strategy_dict_dqn[f'h={i}'][f'epsilon_decay={j}'].append([agent1.own_memory[agent1.play_times-10:agent1.play_times].numpy().astype(int).tolist(), agent2.own_memory[agent2.play_times-10:agent2.play_times].numpy().astype(int).tolist()])\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent1.loss)}, average of loss (interval is 2): {np.mean(agent1.loss[::2])}, average of loss (interval is 20): {np.mean(agent1.loss[::20])}, average of loss (interval is 100): {np.mean(agent1.loss[::100])}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [20000, 3000, 20000, 20000, 4000],\n",
       "  'epsilon_decay=0.99': [20000, 5000, 20000, 20000, 4000],\n",
       "  'epsilon_decay=0.995': [20000, 18000, 3000, 6000, 20000],\n",
       "  'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]},\n",
       " 'h=2': {'epsilon_decay=0.95': [3000, 20000, 4000, 4000, 20000],\n",
       "  'epsilon_decay=0.99': [20000, 5000, 3000, 20000, 20000],\n",
       "  'epsilon_decay=0.995': [5000, 20000, 20000, 18000, 18000],\n",
       "  'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]},\n",
       " 'h=5': {'epsilon_decay=0.95': [3000, 4000, 6000, 3000, 18000],\n",
       "  'epsilon_decay=0.99': [20000, 5000, 20000, 20000, 4000],\n",
       "  'epsilon_decay=0.995': [20000, 20000, 4000, 8000, 20000],\n",
       "  'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]},\n",
       " 'h=10': {'epsilon_decay=0.95': [3000, 20000, 13000, 3000, 11000],\n",
       "  'epsilon_decay=0.99': [20000, 8000, 20000, 20000, 20000],\n",
       "  'epsilon_decay=0.995': [20000, 4000, 20000, 20000, 20000],\n",
       "  'epsilon_decay=0.999': [20000, 20000, 20000, 20000, 20000]}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 1, 1, 0, 1, 1, 0, 1, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.99': [[[0, 1, 0, 1, 0, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 0, 1, 1, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1]],\n",
       "   [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=2': {'epsilon_decay=0.95': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.999': [[[0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=5': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.99': [[[0, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
       "    [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]],\n",
       "  'epsilon_decay=0.995': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 0, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 0, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=10': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
       "    [1, 1, 1, 1, 1, 0, 1, 0, 1, 1]],\n",
       "   [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0]]],\n",
       "  'epsilon_decay=0.999': [[[0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "    [0, 0, 1, 0, 0, 1, 0, 0, 1, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 0, 1]],\n",
       "   [[1, 0, 1, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_dict_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.787715951313224\n",
      "7.0768090728648145\n",
      "8.595668000553706\n",
      "5.504095430615758\n",
      "7.706253216702057\n",
      "7.208648023710969\n",
      "6.405157787942431\n",
      "6.026369777740031\n",
      "7.165410507373098\n",
      "6.166338333760331\n",
      "5.14131538263794\n",
      "6.066017281508488\n",
      "11.990292821132114\n",
      "9.489932365717634\n",
      "5.2823971095843785\n",
      "5.448982174054747\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(np.array(loss_dict_dqn[f'h={i}'][f'epsilon_decay={j}'])[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN vs TfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 2000\n",
      "length of loss: 1936, average of loss (interval is 2): 0.10399050374947488, average of loss (interval is 20): 0.11866714815979912, average of loss (interval is 100): 0.10686213557346491\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.33830433815402033, average of loss (interval is 20): 0.4948061129347925, average of loss (interval is 100): 0.1756123941411109\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.33071988136010705, average of loss (interval is 20): 0.496171795211043, average of loss (interval is 100): 0.15325985363063713\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 0.22809146925124613, average of loss (interval is 20): 0.3786416983417464, average of loss (interval is 100): 0.06933333769460054\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 2000\n",
      "length of loss: 1936, average of loss (interval is 2): 0.10935043796428642, average of loss (interval is 20): 0.12487484408975738, average of loss (interval is 100): 0.0951028875711927\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.32980766723006694, average of loss (interval is 20): 0.5054600031816379, average of loss (interval is 100): 0.1491674229813119\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.3216701871810314, average of loss (interval is 20): 0.49251258162985323, average of loss (interval is 100): 0.14089839009102434\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 0.2533278701916292, average of loss (interval is 20): 0.41126308296856895, average of loss (interval is 100): 0.08662758292164653\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.09283683024214356, average of loss (interval is 20): 0.1029433965224264, average of loss (interval is 100): 0.08512134655296298\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.33590154622793716, average of loss (interval is 20): 0.5214462452699774, average of loss (interval is 100): 0.17405106256871175\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.3220266202195772, average of loss (interval is 20): 0.4867291516427594, average of loss (interval is 100): 0.15345449231390376\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 0.24875941550173866, average of loss (interval is 20): 0.4092142855268557, average of loss (interval is 100): 0.08413492239662446\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.09488784248289955, average of loss (interval is 20): 0.10428640783544203, average of loss (interval is 100): 0.08100225817082295\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.3173423274805851, average of loss (interval is 20): 0.48650419366424014, average of loss (interval is 100): 0.1423019271188726\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.328706436706389, average of loss (interval is 20): 0.5042815958419734, average of loss (interval is 100): 0.13848749980097635\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 0.22956713415700164, average of loss (interval is 20): 0.38392503771600256, average of loss (interval is 100): 0.08150700098194648\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_drqn_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict_drqn_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_drqn_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "\n",
    "for key in result_dict_drqn_t:\n",
    "    result_dict_drqn_t[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict_drqn_t[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_drqn_t[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        n_num = 2\n",
    "        rl_num = 10\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[n_num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_drqn_t[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict_drqn_t[f'h={i}'][f'epsilon_decay={j}'].append(np.mean(agent2.loss))\n",
    "                strategy_dict_drqn_t[f'h={i}'][f'epsilon_decay={j}'].append(agent2.own_memory[agent2.play_times-10:agent2.play_times].numpy().astype(int).tolist())\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [3000, 3000, 3000, 3000, 2000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [6000, 5000, 6000, 5000, 6000]},\n",
       " 'h=2': {'epsilon_decay=0.95': [3000, 2000, 2000, 2000, 2000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [6000, 6000, 6000, 5000, 5000]},\n",
       " 'h=5': {'epsilon_decay=0.95': [3000, 2000, 3000, 2000, 3000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [7000, 6000, 6000, 6000, 5000]},\n",
       " 'h=10': {'epsilon_decay=0.95': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [5000, 6000, 6000, 6000, 6000]}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_drqn_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "  'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       " 'h=2': {'epsilon_decay=0.95': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "  'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       " 'h=5': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "  'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       " 'h=10': {'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "  'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_dict_drqn_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14955716687125167\n",
      "0.32202200703229\n",
      "0.31961403267176447\n",
      "0.22819994771071772\n",
      "0.10022256314383701\n",
      "0.3143290042001776\n",
      "0.31912981373774035\n",
      "0.23007589212767704\n",
      "0.29201921030987105\n",
      "0.32237076219563315\n",
      "0.31479959637606914\n",
      "0.22131568557035958\n",
      "0.2689748312757962\n",
      "0.31211304511570065\n",
      "0.3172150835656422\n",
      "0.22538436881343943\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(loss_dict_drqn_t[f'h={i}'][f'epsilon_decay={j}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN vs DRQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.6526697659626508, average of loss (interval is 20): 0.6657035927524567, average of loss (interval is 100): 0.5939308361465616\n",
      "length of loss: 2936, average of loss (interval is 2): 0.1415143483039591, average of loss (interval is 20): 0.13582485945880762, average of loss (interval is 100): 0.11111775233306011\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.17202555021594662, average of loss (interval is 20): 0.18493436405741995, average of loss (interval is 100): 0.1769069066460361\n",
      "length of loss: 2936, average of loss (interval is 2): 0.19043408928435976, average of loss (interval is 20): 0.2088051033207769, average of loss (interval is 100): 0.19641617928330865\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.28112980696441986, average of loss (interval is 20): 0.29943622291738686, average of loss (interval is 100): 0.27657602447628354\n",
      "length of loss: 2936, average of loss (interval is 2): 0.2508118461398791, average of loss (interval is 20): 0.2713821600893648, average of loss (interval is 100): 0.24640374282413782\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 0.4197146975927793, average of loss (interval is 20): 0.43187935771810027, average of loss (interval is 100): 0.405682564440649\n",
      "length of loss: 4936, average of loss (interval is 2): 0.4351422311987485, average of loss (interval is 20): 0.4434964354795702, average of loss (interval is 100): 0.4083843929885188\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 0.3461834875256691, average of loss (interval is 20): 0.4132758482182215, average of loss (interval is 100): 0.24776351552645792\n",
      "length of loss: 3936, average of loss (interval is 2): 0.526272758591813, average of loss (interval is 20): 0.5862942302564388, average of loss (interval is 100): 0.2832330978779282\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.17652394495562193, average of loss (interval is 20): 0.18768963237267772, average of loss (interval is 100): 0.1669609052274609\n",
      "length of loss: 2936, average of loss (interval is 2): 0.2014825214766209, average of loss (interval is 20): 0.22439760038449305, average of loss (interval is 100): 0.21617527269991116\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.31120544246402637, average of loss (interval is 20): 0.33518978393375104, average of loss (interval is 100): 0.32655682708524786\n",
      "length of loss: 2936, average of loss (interval is 2): 0.2251323574707091, average of loss (interval is 20): 0.24030584061390017, average of loss (interval is 100): 0.22668833470136937\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 0.3788774468808476, average of loss (interval is 20): 0.3859765020070125, average of loss (interval is 100): 0.3637065339228381\n",
      "length of loss: 5936, average of loss (interval is 2): 0.34315870300945045, average of loss (interval is 20): 0.3552494829789622, average of loss (interval is 100): 0.3298460257288146\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.3528277015724308, average of loss (interval is 20): 0.3726866310520483, average of loss (interval is 100): 0.34449386637091567\n",
      "length of loss: 2936, average of loss (interval is 2): 0.07785740229906743, average of loss (interval is 20): 0.08797811624167573, average of loss (interval is 100): 0.06454877544504901\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.19281125941152175, average of loss (interval is 20): 0.20425863297768831, average of loss (interval is 100): 0.18104609894993093\n",
      "length of loss: 2936, average of loss (interval is 2): 0.22745422300721999, average of loss (interval is 20): 0.25073466529162947, average of loss (interval is 100): 0.2521445469804651\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.2526393285131476, average of loss (interval is 20): 0.2620224687117382, average of loss (interval is 100): 0.25243321985471995\n",
      "length of loss: 2936, average of loss (interval is 2): 0.32247754647990995, average of loss (interval is 20): 0.3280108306411248, average of loss (interval is 100): 0.3304052663870001\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 0.41007324455092836, average of loss (interval is 20): 0.42684965767392, average of loss (interval is 100): 0.3762861192406854\n",
      "length of loss: 4936, average of loss (interval is 2): 0.39662571261903373, average of loss (interval is 20): 0.40845462720431597, average of loss (interval is 100): 0.3824441082899284\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 1.2995826105044657, average of loss (interval is 20): 1.4000101721338134, average of loss (interval is 100): 1.1315500372606038\n",
      "length of loss: 3936, average of loss (interval is 2): 0.9955691047924238, average of loss (interval is 20): 1.1591022541870004, average of loss (interval is 100): 0.804607459478575\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.24617277398932197, average of loss (interval is 20): 0.2572297518623216, average of loss (interval is 100): 0.24088269153520134\n",
      "length of loss: 2936, average of loss (interval is 2): 0.17137975524918023, average of loss (interval is 20): 0.1752142835971519, average of loss (interval is 100): 0.16514393176597272\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "length of loss: 2936, average of loss (interval is 2): 0.24125225534096276, average of loss (interval is 20): 0.255519320686678, average of loss (interval is 100): 0.22603806671343232\n",
      "length of loss: 2936, average of loss (interval is 2): 0.24723534651836143, average of loss (interval is 20): 0.267442989480038, average of loss (interval is 100): 0.247564994061698\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 0.42165089816987117, average of loss (interval is 20): 0.4429491426999374, average of loss (interval is 100): 0.3822740317049829\n",
      "length of loss: 4936, average of loss (interval is 2): 0.3822657499767378, average of loss (interval is 20): 0.3951009808897873, average of loss (interval is 100): 0.3517517721158219\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_drqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict_drqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_drqn={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "\n",
    "for key in result_dict_drqn:\n",
    "    result_dict_drqn[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict_drqn[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_drqn[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        rl_num = 10\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[rl_num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_drqn[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict_drqn[f'h={i}'][f'epsilon_decay={j}'].append([np.mean(agent1.loss),np.mean(agent2.loss)])\n",
    "                strategy_dict_drqn[f'h={i}'][f'epsilon_decay={j}'].append([agent1.own_memory[agent1.play_times-10:agent1.play_times].numpy().astype(int).tolist(), agent2.own_memory[agent2.play_times-10:agent2.play_times].numpy().astype(int).tolist()])\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent1.loss)}, average of loss (interval is 2): {np.mean(agent1.loss[::2])}, average of loss (interval is 20): {np.mean(agent1.loss[::20])}, average of loss (interval is 100): {np.mean(agent1.loss[::100])}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [3000, 4000, 3000, 4000, 3000],\n",
       "  'epsilon_decay=0.99': [3000, 5000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [6000, 5000, 6000, 6000, 5000]},\n",
       " 'h=2': {'epsilon_decay=0.95': [4000, 3000, 3000, 3000, 4000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [6000, 5000, 6000, 5000, 6000]},\n",
       " 'h=5': {'epsilon_decay=0.95': [3000, 3000, 4000, 4000, 3000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [5000, 6000, 6000, 5000, 5000]},\n",
       " 'h=10': {'epsilon_decay=0.95': [3000, 4000, 3000, 3000, 4000],\n",
       "  'epsilon_decay=0.99': [3000, 4000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.995': [3000, 3000, 3000, 3000, 3000],\n",
       "  'epsilon_decay=0.999': [5000, 6000, 6000, 6000, 5000]}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_drqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=2': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=5': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=10': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_dict_drqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541613318540993\n",
      "0.23367255136915593\n",
      "0.25134189097108084\n",
      "0.3811893631586258\n",
      "0.6240091759693913\n",
      "0.2727832893012461\n",
      "0.3144180846513758\n",
      "0.37814567458965065\n",
      "0.6750504486773959\n",
      "0.3165014527001072\n",
      "0.27966370917910305\n",
      "0.3883578428508924\n",
      "0.5543067492746468\n",
      "0.45279564580553255\n",
      "0.26032672400135487\n",
      "0.3807973351521633\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(np.array(loss_dict_drqn[f'h={i}'][f'epsilon_decay={j}'])[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QLearning vs TfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 6000\n",
      "==================================================\n",
      "QLearning play 6000 rounds\n",
      "Q_table:\n",
      "tensor([[ 87.7800, 213.4048],\n",
      "        [211.8785, 128.9350]])\n",
      "Your action: tensor([1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Oppo action: tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 2.1978, 56.2419],\n",
      "        [57.2711, 80.9001]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[12.4164, 63.3221],\n",
      "        [63.8502, 82.8192]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 6000\n",
      "==================================================\n",
      "QLearning play 6000 rounds\n",
      "Q_table:\n",
      "tensor([[ 73.7112, 104.5930],\n",
      "        [103.1428, 103.7625]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 0.2800, 48.5273],\n",
      "        [49.7450, 84.0281]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 6.4982, 57.6017],\n",
      "        [58.4434, 80.3472]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[13.5956, 58.8838],\n",
      "        [59.3868, 84.3853]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 5000\n",
      "==================================================\n",
      "QLearning play 5000 rounds\n",
      "Q_table:\n",
      "tensor([[ 74.7192, 101.9708],\n",
      "        [100.6654, 101.7046]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 2000\n",
      "==================================================\n",
      "QLearning play 2000 rounds\n",
      "Q_table:\n",
      "tensor([[ 0.5997, 25.1940],\n",
      "        [25.9971, 75.4884]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 5.5436, 45.2513],\n",
      "        [46.1240, 86.7200]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 9.4865, 56.2935],\n",
      "        [56.8373, 85.5176]])\n",
      "Your action: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 6000\n",
      "==================================================\n",
      "QLearning play 6000 rounds\n",
      "Q_table:\n",
      "tensor([[ 82.7600, 104.5915],\n",
      "        [103.1667, 103.2369]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n",
      "playing times: 20000\n",
      "==================================================\n",
      "QLearning play 20000 rounds\n",
      "Q_table:\n",
      "tensor([[267.4260, 243.3625],\n",
      "        [239.6661, 215.9104]])\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[ 5.2804, 51.8707],\n",
      "        [52.8886, 83.8561]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 3000\n",
      "==================================================\n",
      "QLearning play 3000 rounds\n",
      "Q_table:\n",
      "tensor([[13.3846, 64.9323],\n",
      "        [65.1533, 85.3062]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing times: 6000\n",
      "==================================================\n",
      "QLearning play 6000 rounds\n",
      "Q_table:\n",
      "tensor([[ 77.9678, 102.8538],\n",
      "        [101.4865, 102.3831]])\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_q={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_q={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "\n",
    "for key in result_dict_q:\n",
    "    result_dict_q[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_q[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        n_num = 2\n",
    "        rl_num = 7\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[n_num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_q[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                strategy_dict_q[f'h={i}'][f'epsilon_decay={j}'].append(list(agent2.own_memory[agent2.play_times-10:agent2.play_times]))\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN-Varient vs TfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 2000\n",
      "length of loss: 1936, average of loss (interval is 2): 19.958214418566207, average of loss (interval is 20): 20.756882024564078, average of loss (interval is 100): 17.16371552553028\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 10000\n",
      "length of loss: 9936, average of loss (interval is 2): 4.62382058109342, average of loss (interval is 20): 4.710781207529292, average of loss (interval is 100): 4.070250947065651\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 13000\n",
      "length of loss: 12936, average of loss (interval is 2): 8.826879550502868, average of loss (interval is 20): 9.040137135315762, average of loss (interval is 100): 8.299150878190995\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 9000\n",
      "length of loss: 8936, average of loss (interval is 2): 3.070064821444375, average of loss (interval is 20): 3.2152523397399273, average of loss (interval is 100): 2.5747495233184763\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 2.3017682696596107, average of loss (interval is 20): 2.4064623390130584, average of loss (interval is 100): 1.8522252976894378\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 11000\n",
      "length of loss: 10936, average of loss (interval is 2): 11.25660619645154, average of loss (interval is 20): 11.566764407952945, average of loss (interval is 100): 9.323045201887462\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 7000\n",
      "length of loss: 6936, average of loss (interval is 2): 6.4720408293620535, average of loss (interval is 20): 6.871469725481629, average of loss (interval is 100): 5.866371032702071\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 8000\n",
      "length of loss: 7936, average of loss (interval is 2): 3.673919592934732, average of loss (interval is 20): 3.87405153952295, average of loss (interval is 100): 3.607963405176997\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 3.295076610522375, average of loss (interval is 20): 3.2656261709892207, average of loss (interval is 100): 2.6482125665992498\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 10.870387757297742, average of loss (interval is 20): 11.059590407950783, average of loss (interval is 100): 10.196040250994265\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 8.808788429926253, average of loss (interval is 20): 9.101889320815403, average of loss (interval is 100): 7.370192728936672\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 13000\n",
      "length of loss: 12936, average of loss (interval is 2): 10.642485375268167, average of loss (interval is 20): 10.494222898102455, average of loss (interval is 100): 8.96417506437462\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n",
      "playing times: 9000\n",
      "length of loss: 8936, average of loss (interval is 2): 6.315018670720147, average of loss (interval is 20): 6.489752098951297, average of loss (interval is 100): 5.586386480099625\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 18.558625972017047, average of loss (interval is 20): 18.81370179541409, average of loss (interval is 100): 16.31027771634981\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 2.7641617364933473, average of loss (interval is 20): 2.831032384867747, average of loss (interval is 100): 2.1133097924292086\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 20000\n",
      "length of loss: 19936, average of loss (interval is 2): 10.998760930833091, average of loss (interval is 20): 11.111747152796958, average of loss (interval is 100): 10.90300083855167\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# choices = {'0-alwaysCooperate','1-alwaysDefect','2-titForTat','3-reverseTitForTat','4-random','5-grudger','6-pavlov','7-qLearning','8-lstm-TFT','9-dqn','10-lstmqn','11-a2c','12-a2c-lstm'}\n",
    "# rl_choices = {'7-qLearning','8-lstm-pavlov','9-dqn','10-lstmqn','11-a2c','12-a2c-lstm'}\n",
    "strategies = {0:'ALLC',1:'ALLD',2:'TitForTat',3:'revTitForTat',4:'Random',5:'Grudger',6:'Pavlov',7:'QLearning',8:'LSTM',9:'DQN',10:'LSTMQN',11:'A2C',12:'A2CLSTM'}\n",
    "\n",
    "h = [1,2,5,10]\n",
    "epsilon_decay = [0.95, 0.99, 0.995, 0.999]\n",
    "\n",
    "config = {\n",
    "    'reward': 3, \n",
    "    'sucker': 0, \n",
    "    'temptation': 5, \n",
    "    'punishment': 1, \n",
    "    'n_episodes': 10000, \n",
    "    'discount': 0.99,\n",
    "    'play_epsilon': 1,\n",
    "    'select_epsilon': 1,\n",
    "    'epsilon_decay': 0.999,\n",
    "    'min_epsilon': 0.01,\n",
    "    'alpha': 0.1,\n",
    "    'n_actions': 2,\n",
    "    'h': 10,\n",
    "    'state_repr': 'bi-repr',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "}\n",
    "\n",
    "result_dict_drqnv_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict_drqnv_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_drqnv_t={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "                \n",
    "for key in result_dict_drqnv_t:\n",
    "    result_dict_drqnv_t[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict_drqnv_t[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_drqnv_t[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        num = 2\n",
    "        rl_num = 10\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            # twoSimulate(dict({num: strategies[num],rl_num: strategies[rl_num]}), rl_num, config)\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}'].append(np.mean(agent2.loss))\n",
    "                strategy_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}'].append(list(agent2.own_memory[agent2.play_times-10:agent2.play_times]))\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [3000, 2000, 3000, 3000, 2000],\n",
       "  'epsilon_decay=0.99': [3000, 18000, 13000, 20000, 10000],\n",
       "  'epsilon_decay=0.995': [7000, 8000, 20000, 5000, 13000],\n",
       "  'epsilon_decay=0.999': [16000, 6000, 7000, 13000, 9000]},\n",
       " 'h=2': {'epsilon_decay=0.95': [5000, 3000, 4000, 20000, 4000],\n",
       "  'epsilon_decay=0.99': [10000, 3000, 4000, 16000, 11000],\n",
       "  'epsilon_decay=0.995': [9000, 11000, 7000, 10000, 7000],\n",
       "  'epsilon_decay=0.999': [20000, 7000, 19000, 20000, 8000]},\n",
       " 'h=5': {'epsilon_decay=0.95': [5000, 3000, 3000, 4000, 4000],\n",
       "  'epsilon_decay=0.99': [3000, 3000, 10000, 6000, 20000],\n",
       "  'epsilon_decay=0.995': [15000, 20000, 10000, 5000, 6000],\n",
       "  'epsilon_decay=0.999': [8000, 16000, 7000, 8000, 13000]},\n",
       " 'h=10': {'epsilon_decay=0.95': [3000, 20000, 9000, 6000, 9000],\n",
       "  'epsilon_decay=0.99': [5000, 8000, 5000, 13000, 6000],\n",
       "  'epsilon_decay=0.995': [10000, 12000, 17000, 4000, 4000],\n",
       "  'epsilon_decay=0.999': [11000, 11000, 7000, 6000, 20000]}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_drqnv_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=1\n",
      "{'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
      "h=2\n",
      "{'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
      "h=5\n",
      "{'epsilon_decay=0.95': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.99': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
      "h=10\n",
      "{'epsilon_decay=0.95': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.99': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'epsilon_decay=0.995': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'epsilon_decay=0.999': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        strategy_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}'] = torch.Tensor(strategy_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}']).numpy().astype(int).tolist()\n",
    "    print(f'h={i}')\n",
    "    print(strategy_dict_drqnv_t[f'h={i}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.414868480210291\n",
      "64.1770756559956\n",
      "7.172251405337815\n",
      "12.621518122548967\n",
      "15.981460710378439\n",
      "10.155779616291039\n",
      "8.0922326763928\n",
      "7.329782502905262\n",
      "9.076925424397809\n",
      "8.973471412228323\n",
      "6.925937601916589\n",
      "11.510299137688111\n",
      "7.22495812126611\n",
      "12.386840782386141\n",
      "6.774935636954588\n",
      "10.22713355665719\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(np.array(loss_dict_drqnv_t[f'h={i}'][f'epsilon_decay={j}'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN-Varient vs DRQN-Varient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: h=1, epsilon_decay=0.95\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 3.873874127867348, average of loss (interval is 20): 3.979258805663899, average of loss (interval is 100): 3.188942242289583\n",
      "length of loss: 5936, average of loss (interval is 2): 1.9740417012050522, average of loss (interval is 20): 2.0249151966067327, average of loss (interval is 100): 1.6428610040495792\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.99\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 5.398667894546094, average of loss (interval is 20): 5.473265752120671, average of loss (interval is 100): 4.036063334345817\n",
      "length of loss: 3936, average of loss (interval is 2): 3.614369572677869, average of loss (interval is 20): 3.5694336149898276, average of loss (interval is 100): 3.6719582259654997\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.995\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 4.6889171885813505, average of loss (interval is 20): 4.820793213467004, average of loss (interval is 100): 4.622375597556432\n",
      "length of loss: 5936, average of loss (interval is 2): 6.536930904676008, average of loss (interval is 20): 6.880540465064322, average of loss (interval is 100): 7.353381438056628\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=1, epsilon_decay=0.999\n",
      "playing times: 8000\n",
      "length of loss: 7936, average of loss (interval is 2): 6.345438184100203, average of loss (interval is 20): 6.732873439413474, average of loss (interval is 100): 6.1131264545023445\n",
      "length of loss: 7936, average of loss (interval is 2): 11.123820175367948, average of loss (interval is 20): 11.663675636278292, average of loss (interval is 100): 10.822411554306745\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.95\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 2.377161040609307, average of loss (interval is 20): 2.4436465846261517, average of loss (interval is 100): 2.095483028292656\n",
      "length of loss: 4936, average of loss (interval is 2): 1.9245762957827561, average of loss (interval is 20): 1.888517478790119, average of loss (interval is 100): 1.5918231754004954\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.99\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 3.7395386694271755, average of loss (interval is 20): 3.89160987621334, average of loss (interval is 100): 2.8096957616508007\n",
      "length of loss: 3936, average of loss (interval is 2): 1.5975247180672378, average of loss (interval is 20): 1.6387716573733968, average of loss (interval is 100): 1.4428710300475358\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.995\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 1.1409051725527317, average of loss (interval is 20): 1.1852391615585627, average of loss (interval is 100): 0.9891822412610054\n",
      "length of loss: 3936, average of loss (interval is 2): 1.823040448409331, average of loss (interval is 20): 1.8512742479289244, average of loss (interval is 100): 1.5352843910455705\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=2, epsilon_decay=0.999\n",
      "playing times: 9000\n",
      "length of loss: 8936, average of loss (interval is 2): 3.5113263382320437, average of loss (interval is 20): 3.428119462608491, average of loss (interval is 100): 3.081905725267198\n",
      "length of loss: 8936, average of loss (interval is 2): 5.332913497607945, average of loss (interval is 20): 5.469030027154841, average of loss (interval is 100): 4.825574829843309\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.95\n",
      "playing times: 6000\n",
      "length of loss: 5936, average of loss (interval is 2): 5.407220166992406, average of loss (interval is 20): 5.370682610430902, average of loss (interval is 100): 4.700966972236832\n",
      "length of loss: 5936, average of loss (interval is 2): 6.629048441418741, average of loss (interval is 20): 6.796233576405731, average of loss (interval is 100): 6.346116063495477\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.99\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 3.9087496024135326, average of loss (interval is 20): 4.2323964392306355, average of loss (interval is 100): 3.599701838940382\n",
      "length of loss: 4936, average of loss (interval is 2): 3.8510360589109034, average of loss (interval is 20): 3.7138517421749437, average of loss (interval is 100): 3.5904862174391745\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.995\n",
      "playing times: 8000\n",
      "length of loss: 7936, average of loss (interval is 2): 7.56851613398401, average of loss (interval is 20): 7.4530314412765595, average of loss (interval is 100): 6.421553915739059\n",
      "length of loss: 7936, average of loss (interval is 2): 6.915713967920672, average of loss (interval is 20): 6.814977963565279, average of loss (interval is 100): 6.140446723997593\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=5, epsilon_decay=0.999\n",
      "playing times: 8000\n",
      "length of loss: 7936, average of loss (interval is 2): 3.409895275171185, average of loss (interval is 20): 3.5884866721984423, average of loss (interval is 100): 2.997767370939255\n",
      "length of loss: 7936, average of loss (interval is 2): 7.494139952314717, average of loss (interval is 20): 7.860721205133635, average of loss (interval is 100): 6.260141317546368\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.95\n",
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 3.863617747985853, average of loss (interval is 20): 3.860504026113734, average of loss (interval is 100): 3.790712978243828\n",
      "length of loss: 4936, average of loss (interval is 2): 1.8754422052761892, average of loss (interval is 20): 1.9289054970901747, average of loss (interval is 100): 1.506826521754265\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing times: 5000\n",
      "length of loss: 4936, average of loss (interval is 2): 3.8621226131185478, average of loss (interval is 20): 4.048364943639952, average of loss (interval is 100): 3.0765360298752786\n",
      "length of loss: 4936, average of loss (interval is 2): 1.6482140220825467, average of loss (interval is 20): 1.7004396611078065, average of loss (interval is 100): 1.741843352019787\n",
      "==================================================\n",
      "Your action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.995\n",
      "playing times: 4000\n",
      "length of loss: 3936, average of loss (interval is 2): 2.115105207630895, average of loss (interval is 20): 2.142013110939016, average of loss (interval is 100): 1.848880621790886\n",
      "length of loss: 3936, average of loss (interval is 2): 2.1006690108982045, average of loss (interval is 20): 2.127445940438866, average of loss (interval is 100): 2.1139034181833267\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "\n",
      "\n",
      "config: h=10, epsilon_decay=0.999\n",
      "playing times: 8000\n",
      "length of loss: 7936, average of loss (interval is 2): 1.9049101591395634, average of loss (interval is 20): 1.9611147826804922, average of loss (interval is 100): 1.74265448898077\n",
      "length of loss: 7936, average of loss (interval is 2): 1.6361115177447396, average of loss (interval is 20): 1.6630933302776039, average of loss (interval is 100): 1.6273754708468915\n",
      "==================================================\n",
      "Your action: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Oppo action: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_drqnv={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "loss_dict_drqnv={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "strategy_dict_drqnv={'h=1':{}, 'h=2':{}, 'h=5':{}, 'h=10':{}}\n",
    "                \n",
    "for key in result_dict_drqnv:\n",
    "    result_dict_drqnv[key] = copy.deepcopy(epsilon_dict)\n",
    "    loss_dict_drqnv[key] = copy.deepcopy(epsilon_dict)\n",
    "    strategy_dict_drqnv[key] = copy.deepcopy(epsilon_dict)\n",
    "\n",
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        config['h'] = 1\n",
    "        config['epsilon_decay'] = j\n",
    "        config_ob = Config(config)\n",
    "        env = Environment(config_ob)\n",
    "        print(f'config: h={i}, epsilon_decay={j}')\n",
    "        \n",
    "        rl_num = 10\n",
    "        for _ in range(5):\n",
    "            convergence = False\n",
    "            # twoSimulate(dict({num: strategies[num],rl_num: strategies[rl_num]}), rl_num, config)\n",
    "            with HiddenPrints():\n",
    "                agent1 = constructAgent(strategies[rl_num], config_ob)\n",
    "                agent2 = constructAgent(strategies[rl_num], config_ob)\n",
    "\n",
    "                k = 1000\n",
    "                while not convergence:\n",
    "                    env.play(agent1, agent2, k)\n",
    "                    convergence = determine_convergence(agent2, 20, k=k)\n",
    "                    if agent2.play_times >= 20*k:\n",
    "                        break\n",
    "        \n",
    "                result_dict_drqnv[f'h={i}'][f'epsilon_decay={j}'].append(agent2.play_times)\n",
    "                loss_dict_drqnv[f'h={i}'][f'epsilon_decay={j}'].append([np.mean(agent1.loss),np.mean(agent2.loss)])\n",
    "                strategy_dict_drqnv[f'h={i}'][f'epsilon_decay={j}'].append([agent1.own_memory[agent1.play_times-10:agent1.play_times].numpy().astype(int).tolist(), agent2.own_memory[agent2.play_times-10:agent2.play_times].numpy().astype(int).tolist()])\n",
    "        print(f'playing times: {agent2.play_times}')\n",
    "        print(f'length of loss: {len(agent1.loss)}, average of loss (interval is 2): {np.mean(agent1.loss[::2])}, average of loss (interval is 20): {np.mean(agent1.loss[::20])}, average of loss (interval is 100): {np.mean(agent1.loss[::100])}')\n",
    "        print(f'length of loss: {len(agent2.loss)}, average of loss (interval is 2): {np.mean(agent2.loss[::2])}, average of loss (interval is 20): {np.mean(agent2.loss[::20])}, average of loss (interval is 100): {np.mean(agent2.loss[::100])}')\n",
    "        agent2.show()\n",
    "        print()\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [13000, 6000, 2000, 13000, 6000],\n",
       "  'epsilon_decay=0.99': [3000, 6000, 4000, 3000, 4000],\n",
       "  'epsilon_decay=0.995': [5000, 8000, 4000, 5000, 6000],\n",
       "  'epsilon_decay=0.999': [8000, 6000, 6000, 10000, 8000]},\n",
       " 'h=2': {'epsilon_decay=0.95': [5000, 5000, 4000, 7000, 5000],\n",
       "  'epsilon_decay=0.99': [3000, 4000, 3000, 3000, 4000],\n",
       "  'epsilon_decay=0.995': [5000, 4000, 5000, 3000, 4000],\n",
       "  'epsilon_decay=0.999': [7000, 6000, 6000, 7000, 9000]},\n",
       " 'h=5': {'epsilon_decay=0.95': [11000, 2000, 6000, 3000, 6000],\n",
       "  'epsilon_decay=0.99': [3000, 5000, 18000, 4000, 5000],\n",
       "  'epsilon_decay=0.995': [4000, 4000, 3000, 4000, 8000],\n",
       "  'epsilon_decay=0.999': [9000, 6000, 6000, 9000, 8000]},\n",
       " 'h=10': {'epsilon_decay=0.95': [3000, 4000, 2000, 2000, 5000],\n",
       "  'epsilon_decay=0.99': [5000, 6000, 5000, 5000, 5000],\n",
       "  'epsilon_decay=0.995': [3000, 6000, 3000, 4000, 4000],\n",
       "  'epsilon_decay=0.999': [10000, 8000, 8000, 7000, 8000]}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_drqnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h=1': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]},\n",
       " 'h=2': {'epsilon_decay=0.95': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.99': [[[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.999': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=5': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]},\n",
       " 'h=10': {'epsilon_decay=0.95': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.99': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "  'epsilon_decay=0.995': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "  'epsilon_decay=0.999': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_dict_drqnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.71502027226603\n",
      "3.0871757431699516\n",
      "3.9225479145171795\n",
      "4.036711904387093\n",
      "3.3467126590067187\n",
      "3.0363597030676535\n",
      "2.382156602091908\n",
      "3.1833075166015696\n",
      "6.580258945382764\n",
      "7.736673866204468\n",
      "4.135884103423476\n",
      "4.6798164707273795\n",
      "9.016569304337873\n",
      "4.0369239787560565\n",
      "2.8074456614052847\n",
      "3.3759989282246763\n"
     ]
    }
   ],
   "source": [
    "for i in h:\n",
    "    for j in epsilon_decay:\n",
    "        print(np.mean(np.array(loss_dict_drqnv[f'h={i}'][f'epsilon_decay={j}'])[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
