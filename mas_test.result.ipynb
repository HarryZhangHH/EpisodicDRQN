{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import *\n",
    "from selection import *\n",
    "from utils import *\n",
    "from env import Environment\n",
    "from simulation import constructAgent\n",
    "from main import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_SELECTION_METHOD = 'LSTM-VAR'\n",
    "config = {\n",
    "    'reward': 3, \n",
    "    'sucker': 0, \n",
    "    'temptation': 5, \n",
    "    'punishment': 1, \n",
    "    'n_episodes': 2000, \n",
    "    'discount': 0.95,\n",
    "    'play_epsilon': 1,\n",
    "    'select_epsilon': 1,\n",
    "    'epsilon_decay': 0.99,\n",
    "    'min_epsilon': 0.01,\n",
    "    'alpha': 0.1,\n",
    "    'n_actions': 2,\n",
    "    'h': 10,\n",
    "    'state_repr': 'bi-repr',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "}\n",
    "config = Config(config)\n",
    "env = Environment(config)\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [05:08<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent0: name:LSTMQN  final score:94.90004671163244  play time:2731  times to play D:2668  ratio: 0.9769315269132186\n",
      "Agent1: name:LSTMQN  final score:94.53512405096731  play time:2184  times to play D:2132  ratio: 0.9761904761904762\n",
      "Agent2: name:LSTMQN  final score:72.24022966612773  play time:3234  times to play D:3167  ratio: 0.979282622139765\n",
      "Agent3: name:LSTMQN  final score:56.60100423693475  play time:2379  times to play D:107  ratio: 0.044976881042454814\n",
      "Agent4: name:LSTMQN  final score:30.32478910200641  play time:8108  times to play D:240  ratio: 0.02960039467192896\n",
      "Agent5: name:LSTMQN  final score:76.99412226035001  play time:2061  times to play D:2012  ratio: 0.9762251334303736\n",
      "Agent6: name:LSTMQN  final score:62.46347902188574  play time:4845  times to play D:1363  ratio: 0.28132094943240454\n",
      "Agent7: name:LSTMQN  final score:97.89910376212687  play time:2085  times to play D:2025  ratio: 0.9712230215827338\n",
      "Agent8: name:LSTMQN  final score:48.315518361652174  play time:3602  times to play D:64  ratio: 0.01776790671848973\n",
      "Agent9: name:LSTMQN  final score:34.40361239968132  play time:8771  times to play D:81  ratio: 0.009234978907764223\n",
      "The reward for total society: 106.40332391934403\n"
     ]
    }
   ],
   "source": [
    "agents = {}\n",
    "index = 0\n",
    "with HiddenPrints():\n",
    "    # for _ in range(5):\n",
    "        # agents[index] = constructAgent('TitForTat', config)\n",
    "        # index += 1\n",
    "    for _ in range(10):\n",
    "        agents[index] = constructAgent('LSTMQN', config)\n",
    "        index += 1\n",
    " \n",
    "agents = lstm_variant_selection(config, agents, env)\n",
    "\n",
    "for n in range(len(agents)):\n",
    "    print('Agent{}: name:{}  final score:{}  play time:{}  times to play D:{}  ratio: {}'\n",
    "        .format(n, agents[n].name, agents[n].running_score,\n",
    "        len(agents[n].own_memory[:agents[n].play_times]), list(agents[n].own_memory[:agents[n].play_times]).count(1),\n",
    "                list(agents[n].own_memory[:agents[n].play_times]).count(1)/len(agents[n].own_memory[:agents[n].play_times])))\n",
    "print('The reward for total society: {}'.format(env.running_score/len(agents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0: opponent_idx: [1, 3, 4, 8, 9], counts: [6, 2, 745, 146, 101] rewards: [0.8333333333333334, 1.0, 4.959731543624161, 4.972602739726027, 4.98019801980198]\n",
      "Agent 1: opponent_idx: [0, 3, 4, 6, 8, 9], counts: [29, 1, 1, 62, 501, 406] rewards: [1.0, 1.0, 5.0, 1.5806451612903225, 4.972055888223553, 4.9655172413793105]\n",
      "Agent 2: opponent_idx: [0, 4, 5, 6, 9], counts: [28, 1, 30, 1, 940] rewards: [1.0, 5.0, 1.0, 1.0, 4.965957446808511]\n",
      "Agent 3: opponent_idx: [0, 1, 2, 4, 5, 7, 8, 9], counts: [1, 10, 33, 801, 2, 4, 148, 1] rewards: [1.0, 0.9, 0.8484848484848485, 2.9987515605493136, 1.0, 1.0, 3.0, 3.0]\n",
      "Agent 4: opponent_idx: [0, 1, 2, 3, 5, 6, 8, 9], counts: [2, 2, 15, 8, 7, 303, 52, 611] rewards: [0.0, 0.0, 0.0, 3.0, 0.0, 2.597359735973597, 2.923076923076923, 2.988543371522095]\n",
      "Agent 5: opponent_idx: [0, 4, 6, 8, 9], counts: [1, 1, 3, 18, 977] rewards: [1.0, 5.0, 1.0, 4.888888888888889, 4.981576253838281]\n",
      "Agent 6: opponent_idx: [0, 1, 2, 3, 4, 7, 9], counts: [1, 13, 1, 331, 160, 1, 493] rewards: [1.0, 1.0, 1.0, 3.773413897280967, 3.1875, 1.0, 3.1987829614604464]\n",
      "Agent 7: opponent_idx: [0, 1, 3, 4, 5, 6, 9], counts: [1, 2, 1, 973, 1, 21, 1] rewards: [1.0, 1.0, 1.0, 4.948612538540596, 1.0, 1.0, 5.0]\n",
      "Agent 8: opponent_idx: [0, 1, 3, 4, 6, 9], counts: [35, 1, 1, 28, 275, 660] rewards: [0.0, 0.0, 3.0, 2.892857142857143, 2.2836363636363637, 3.0045454545454544]\n",
      "Agent 9: opponent_idx: [0, 1, 4, 6, 8], counts: [1, 1, 864, 102, 32] rewards: [0.0, 0.0, 2.980324074074074, 2.9411764705882355, 3.0]\n"
     ]
    }
   ],
   "source": [
    "def get_index_from_action(action, idx):\n",
    "    scale = lambda x: x+1 if x>=idx else x\n",
    "    return list(map(scale, action))\n",
    "\n",
    "for idx in agents:\n",
    "    transitions = agents[idx].SelectMemory.memory\n",
    "    _, actions, rewards, _ = zip(*transitions)\n",
    "    actions = get_index_from_action(np.array(actions, dtype=int), idx)\n",
    "    actions, rewards = np.array(actions), np.array(rewards)\n",
    "    print(f'Agent {idx}:', end='')\n",
    "    values, counts = np.unique(actions, return_counts=True)\n",
    "    print(f' opponent_idx: {list(values)}, counts: {list(counts)} ', end='')\n",
    "    dict_idx = {x: rewards[np.where(actions == x)] for x in values}\n",
    "    print(f'rewards: {[np.mean(y) for _, y in dict_idx.items()]}')\n",
    "    # print(f'rewards: {[np.std(y) for _, y in dict_idx.items()]}')\n",
    "# plt.plot(actions)\n",
    "# plt.show()\n",
    "# print(rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
